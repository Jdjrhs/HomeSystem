# LLM厂商配置文件 - 2025年最新版本
# 仅包含32B以上参数的模型（本地Ollama使用14B以上）

providers:
  # DeepSeek AI - 2025年最新模型
  deepseek:
    name: "DeepSeek"
    description: "DeepSeek AI - 深度求索最新V3和R1系列"
    type: "openai_compatible"
    api_key_env: "DEEPSEEK_API_KEY"
    base_url_env: "DEEPSEEK_BASE_URL"
    base_url: "https://api.deepseek.com"
    models:
      - name: "deepseek-chat"  # API实际模型名
        key: "deepseek.DeepSeek_V3"  # 用户调用的标识名
        display_name: "DeepSeek V3"
        parameters: "671B总参数/37B激活"
        max_tokens: 131072
        supports_functions: true
        context_length: 131072
        description: "MoE架构，14.8万亿token训练"
      - name: "deepseek-reasoner"  # API实际模型名
        key: "deepseek.DeepSeek_R1"  # 用户调用的标识名
        display_name: "DeepSeek R1"
        parameters: "推理专用模型"
        max_tokens: 131072
        supports_functions: true
        context_length: 131072
        description: "最新推理模型，AIME 2025达87.5%准确率"

  # 硅基流动 - 2025年最新模型集合
  siliconflow:
    name: "SiliconFlow"
    description: "硅基流动 - 高性能推理平台，支持多种大模型"
    type: "openai_compatible"
    api_key_env: "SILICONFLOW_API_KEY"
    base_url_env: "SILICONFLOW_BASE_URL"
    base_url: "https://api.siliconflow.cn/v1"
    models:
      - name: "deepseek-ai/DeepSeek-R1"
        key: "siliconflow.DeepSeek_R1"
        display_name: "DeepSeek R1 (硅基流动)"
        parameters: "推理优化版本"
        max_tokens: 131072
        supports_functions: true
        context_length: 131072
        description: "通过硅基流动提供的DeepSeek R1"
      - name: "deepseek-ai/DeepSeek-V3"
        key: "siliconflow.DeepSeek_V3"
        display_name: "DeepSeek V3 (硅基流动)"
        parameters: "671B总参数/37B激活"
        max_tokens: 131072
        supports_functions: true
        context_length: 131072
        description: "通过硅基流动提供的DeepSeek V3"
      - name: "Qwen/QwQ-32B-Preview"
        key: "siliconflow.QwQ_32B"
        display_name: "通义千问 QwQ-32B"
        parameters: "32B"
        max_tokens: 32768
        supports_functions: true
        context_length: 32768
        description: "阿里通义千问推理增强版本"
      - name: "Qwen/Qwen2.5-72B-Instruct"
        key: "siliconflow.Qwen2_5_72B"
        display_name: "通义千问 2.5-72B"
        parameters: "72B"
        max_tokens: 131072
        supports_functions: true
        context_length: 131072
        description: "通义千问2.5系列最强版本"

  # 火山引擎 - 豆包1.6系列
  volcano:
    name: "Volcano Engine"
    description: "火山引擎 - 豆包1.6系列大模型"
    type: "openai_compatible"
    api_key_env: "VOLCANO_API_KEY"
    base_url_env: "VOLCANO_BASE_URL"
    base_url: "https://ark.cn-beijing.volces.com/api/v3"
    models:
      - name: "doubao-seed-1.6"
        key: "volcano.Doubao_1_6"
        display_name: "豆包1.6 全能版"
        parameters: "未公开参数量"
        max_tokens: 16384
        supports_functions: true
        context_length: 256000  # 256K上下文
        description: "All-in-One综合模型，支持深度思考和多模态"
      - name: "doubao-seed-1.6-thinking"
        key: "volcano.Doubao_1_6_Thinking"
        display_name: "豆包1.6 深度思考版"
        parameters: "未公开参数量"
        max_tokens: 16384
        supports_functions: true
        context_length: 256000
        description: "深度思考强化版，数学推理能力突出"
      - name: "doubao-seed-1.6-flash"
        key: "volcano.Doubao_1_6_Flash"
        display_name: "豆包1.6 极速版"
        parameters: "未公开参数量"
        max_tokens: 16384
        supports_functions: true
        context_length: 256000  # 256K上下文窗口
        description: "极低延迟版本，TOPT仅需10ms，支持256K上下文"

  # 月之暗面 - Kimi K2万亿参数模型
  moonshot:
    name: "MoonShot"
    description: "月之暗面 - Kimi K2万亿参数智能体模型"
    type: "openai_compatible"
    api_key_env: "MOONSHOT_API_KEY"
    base_url_env: "MOONSHOT_BASE_URL"
    base_url: "https://api.moonshot.cn/v1"
    models:
      - name: "kimi-k2"
        key: "moonshot.Kimi_K2"
        display_name: "Kimi K2"
        parameters: "1T总参数/32B激活"
        max_tokens: 16384
        supports_functions: true
        context_length: 131072  # 128K上下文
        description: "万亿参数MoE智能体模型，专注代码和推理"
      - name: "moonshot-v1-128k"
        key: "moonshot.Kimi_V1_128K"
        display_name: "Kimi v1 128K"
        parameters: "未公开参数量"
        max_tokens: 16384
        supports_functions: true
        context_length: 131072
        description: "长上下文处理专用版本"

  # Ollama - 本地部署14B以上模型
  ollama:
    name: "Ollama"
    description: "本地部署的开源大模型 (14B以上参数)"
    type: "ollama"
    api_key_env: ""  # Ollama不需要API Key
    base_url_env: "OLLAMA_BASE_URL"
    base_url: "http://localhost:11434"
    models:
      - name: "deepseek-r1:14b"
        key: "ollama.DeepSeek_R1_14B"
        display_name: "DeepSeek R1 14B"
        parameters: "14B"
        max_tokens: 32768
        supports_functions: false
        context_length: 131072  # 128K上下文窗口
        description: "DeepSeek推理模型本地版本，支持128K上下文"
      - name: "deepseek-r1:32b"
        key: "ollama.DeepSeek_R1_32B"
        display_name: "DeepSeek R1 32B"
        parameters: "32B"
        max_tokens: 32768
        supports_functions: false
        context_length: 131072  # 128K上下文窗口
        description: "DeepSeek推理模型32B版本，更强性能，支持128K上下文"
      - name: "qwen3:30b"
        key: "ollama.Qwen3_30B"
        display_name: "通义千问3 30B"
        parameters: "30B总参数/3B激活"
        max_tokens: 32768
        supports_functions: false
        context_length: 131072  # 128K上下文窗口
        description: "MoE架构代码专用模型，多语言支持，支持128K上下文"

# Embedding模型配置
embedding_providers:
  # Ollama本地Embedding模型
  ollama_embedding:
    name: "Ollama Embedding"
    description: "本地部署的Embedding模型"
    type: "ollama_embedding"
    api_key_env: ""
    base_url_env: "OLLAMA_BASE_URL"
    base_url: "http://localhost:11434"
    models:
      - name: "bge-m3:latest"
        key: "ollama.BGE_M3"
        display_name: "BGE-M3"
        parameters: "560M"
        dimensions: 1024
        max_input_length: 8192
        description: "BAAI开源的多语言embedding模型，支持中英文"
      - name: "nomic-embed-text:latest"
        key: "ollama.Nomic_Embed_Text"
        display_name: "Nomic Embed Text"
        parameters: "137M"
        dimensions: 768
        max_input_length: 2048
        description: "高效的英文文本embedding模型"
      - name: "mxbai-embed-large:latest"
        key: "ollama.MxBai_Embed_Large"
        display_name: "MxBai Embed Large"
        parameters: "335M"
        dimensions: 1024
        max_input_length: 512
        description: "高质量的通用embedding模型"

  # 在线Embedding服务
  openai_embedding:
    name: "OpenAI Embedding"
    description: "OpenAI提供的embedding服务"
    type: "openai_embedding"
    api_key_env: "OPENAI_API_KEY"
    base_url_env: "OPENAI_BASE_URL"
    base_url: "https://api.openai.com/v1"
    models:
      - name: "text-embedding-3-large"
        key: "openai.Text_Embedding_3_Large"
        display_name: "Text Embedding 3 Large"
        parameters: "未公开"
        dimensions: 3072
        max_input_length: 8191
        description: "OpenAI最新大型embedding模型"
      - name: "text-embedding-3-small"
        key: "openai.Text_Embedding_3_Small"
        display_name: "Text Embedding 3 Small"
        parameters: "未公开"
        dimensions: 1536
        max_input_length: 8191
        description: "OpenAI紧凑型embedding模型"

  # 硅基流动Embedding
  siliconflow_embedding:
    name: "SiliconFlow Embedding"
    description: "硅基流动embedding服务"
    type: "openai_embedding"
    api_key_env: "SILICONFLOW_API_KEY"
    base_url_env: "SILICONFLOW_BASE_URL"
    base_url: "https://api.siliconflow.cn/v1"
    models:
      - name: "BAAI/bge-large-zh-v1.5"
        key: "siliconflow.BGE_Large_ZH_V1_5"
        display_name: "BGE Large 中文 v1.5"
        parameters: "326M"
        dimensions: 1024
        max_input_length: 512
        description: "中文优化的embedding模型"

# 默认配置
defaults:
  # LLM模型默认配置
  llm:
    model_key: "deepseek.DeepSeek_V3"  # 使用新的key格式
    temperature: 0.7
    max_tokens: 4000
    timeout: 60
    context_length: 131072
  
  # Embedding模型默认配置
  embedding:
    model_key: "ollama.BGE_M3"  # 使用新的key格式
    dimensions: 1024
    batch_size: 32
    timeout: 30

# 模型参数配置范围
parameters:
  temperature:
    min: 0.0
    max: 2.0
    default: 0.7
    description: "控制输出的随机性和创造性"
  
  max_tokens:
    min: 1
    max: 131072
    default: 4000
    description: "单次生成的最大token数"
  
  top_p:
    min: 0.0
    max: 1.0
    default: 1.0
    description: "核采样参数，控制词汇选择范围"
  
  frequency_penalty:
    min: -2.0
    max: 2.0
    default: 0.0
    description: "频率惩罚，减少重复内容"
  
  presence_penalty:
    min: -2.0
    max: 2.0
    default: 0.0
    description: "存在惩罚，鼓励主题多样性"

# 厂商特定配置和优化
vendor_configs:
  deepseek:
    retry_attempts: 3
    retry_delay: 1.0
    rate_limit: 100  # 每分钟请求数
    special_headers:
      "User-Agent": "HomeSystem/1.0"
    pricing:
      input_tokens: 0.14  # 美元/百万token (缓存未命中)
      output_tokens: 2.00  # 美元/百万token
      cache_hit: 0.014   # 美元/百万token (缓存命中)

  siliconflow:
    retry_attempts: 3
    retry_delay: 0.5
    rate_limit: 120
    pricing_note: "9B以下模型永久免费"
    
  volcano:
    retry_attempts: 3
    retry_delay: 2.0
    region: "cn-beijing"
    rate_limit: 60
    pricing:
      input_tokens: 0.008  # 美元/百万token (0-32K)
      output_tokens: 0.08  # 美元/百万token
    
  moonshot:
    retry_attempts: 2
    retry_delay: 1.5
    rate_limit: 50
    min_charge: 50  # 最低充值金额(元)
    
  ollama:
    retry_attempts: 1
    retry_delay: 0.1
    local_model: true
    gpu_required: true
    min_vram: "24GB"  # 推荐显存
    note: "需要本地GPU支持，推荐RTX 4090或更高"

# 模型推荐配置
recommendations:
  general_use: "deepseek-chat"  # 通用对话
  reasoning: "deepseek-reasoner"  # 推理任务  
  coding: "qwen2.5-coder:32b"  # 代码任务
  long_context: "doubao-seed-1.6"  # 长文档处理
  local_deployment: "llama3.3:70b"  # 本地部署
  cost_effective: "siliconflow"  # 成本敏感场景

# 性能基准参考
benchmarks:
  deepseek_v3:
    aime_2024: "90%+"
    humaneval: "85%+"
    math: "90%+"
  
  doubao_1_6:
    aime_2025: "86.3分"
    gaokao_math: "144分"
    
  kimi_k2:
    eq_bench3: "排名第一"
    creative_writing_v3: "排名第一"